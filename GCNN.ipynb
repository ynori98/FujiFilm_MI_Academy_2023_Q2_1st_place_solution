{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import rdkit\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv,global_max_pool,AGNNConv,NNConv\n",
    "from torch.nn import ModuleList ,BatchNorm1d,Linear\n",
    "import torch.nn.functional  as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 現在の作業ディレクトリを取得\n",
    "current_directory = os.getcwd()\n",
    "# データセットのパスを取得\n",
    "data_path = os.path.join(current_directory, 'datasets', 'dataset.csv')\n",
    "#データセットを取得\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_atom_feature(smiles : str, res_type='tensor'):\n",
    "    mol = rdkit.Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        mol = rdkit.Chem.MolFromSmiles('')\n",
    "    xs = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        x = []\n",
    "        x.append(atom.GetSymbol() == 'B')\n",
    "        x.append(atom.GetSymbol() == 'C')\n",
    "        x.append(atom.GetSymbol() == 'F')\n",
    "        x.append(atom.GetSymbol() == 'H')\n",
    "        x.append(atom.GetSymbol() == 'N')\n",
    "        x.append(atom.GetSymbol() == 'O')\n",
    "        x.append(atom.GetSymbol() == 'P')\n",
    "        x.append(atom.GetSymbol() == 'S')\n",
    "\n",
    "        x.append(str(atom.GetChiralTag()) == 'CHI_UNSPECIFIED')\n",
    "        x.append(str(atom.GetChiralTag()) == 'CHI_TETRAHEDRAL_CW')\n",
    "        x.append(str(atom.GetChiralTag()) == 'CHI_TETRAHEDRAL_CCW')\n",
    "        x.append(str(atom.GetChiralTag()) == 'CHI_OTHER')\n",
    "\n",
    "        for degree in range(11):\n",
    "            x.append(atom.GetTotalDegree() == degree)\n",
    "\n",
    "        for formal_charge in range(-5,6):\n",
    "            x.append(atom.GetFormalCharge() == formal_charge)\n",
    "\n",
    "        for num_hs in range(7):\n",
    "            x.append(atom.GetTotalNumHs() == num_hs)\n",
    "\n",
    "        for num_radical_electrons in range(10):\n",
    "            x.append(atom.GetNumRadicalElectrons() == num_radical_electrons)\n",
    "            \n",
    "        x.append(str(atom.GetHybridization()) == 'UNSPECIFIED')\n",
    "        x.append(str(atom.GetHybridization()) == 'S')\n",
    "        x.append(str(atom.GetHybridization()) == 'SP')\n",
    "        x.append(str(atom.GetHybridization()) == 'SP2')\n",
    "        x.append(str(atom.GetHybridization()) == 'SP3')\n",
    "        x.append(str(atom.GetHybridization()) == 'SP3D')\n",
    "        x.append(str(atom.GetHybridization()) == 'SP3D2')\n",
    "        x.append(str(atom.GetHybridization()) == 'OTHER')\n",
    "        \n",
    "        x.append(atom.GetIsAromatic() == True)\n",
    "\n",
    "        x.append(atom.IsInRing() == True)\n",
    "\n",
    "        xs.append(x)\n",
    "    if res_type == 'tensor':\n",
    "        xs = torch.tensor(xs,dtype=torch.float32)\n",
    "    elif res_type == 'list':\n",
    "        pass\n",
    "\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_bond_feature(smiles : str):\n",
    "    edge_index = [[],[]]\n",
    "    edge_attr = []\n",
    "    mol = rdkit.Chem.MolFromSmiles(smiles)\n",
    "    for bond in mol.GetBonds():\n",
    "        edge_features = []\n",
    "        edge_index[0].append(bond.GetBeginAtomIdx())\n",
    "        edge_index[0].append(bond.GetEndAtomIdx())\n",
    "        edge_index[1].append(bond.GetEndAtomIdx())\n",
    "        edge_index[1].append(bond.GetBeginAtomIdx())\n",
    "\n",
    "        edge_features.append(str(bond.GetBondType()) == 'misc')\n",
    "        edge_features.append(str(bond.GetBondType()) == 'SINGLE')\n",
    "        edge_features.append(str(bond.GetBondType()) == 'DOUBLE')\n",
    "        edge_features.append(str(bond.GetBondType()) == 'TRIPLE')\n",
    "        edge_features.append(str(bond.GetBondType()) == 'AROMATIC')\n",
    "\n",
    "        \n",
    "        edge_features.append(str(bond.GetStereo()) == 'STEREONONE')\n",
    "        edge_features.append(str(bond.GetStereo()) == 'STEREOZ')\n",
    "        edge_features.append(str(bond.GetStereo()) == 'STEREOE')\n",
    "        edge_features.append(str(bond.GetStereo()) == 'STEREOCIS')\n",
    "        edge_features.append(str(bond.GetStereo()) == 'STEREOTRANS')\n",
    "        edge_features.append(str(bond.GetStereo()) == 'STEREOANY')\n",
    "\n",
    "        edge_features.append(str(bond.GetIsConjugated()) == True)\n",
    "\n",
    "        edge_attr.append(edge_features)\n",
    "        edge_attr.append(edge_features)\n",
    "\n",
    "    edge_index = torch.tensor(edge_index,dtype=torch.long)\n",
    "    edge_attr = torch.tensor(edge_attr,dtype=torch.float32)\n",
    "\n",
    "    return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolecularGCN2(torch.nn.Module):\n",
    "    def __init__(self, node_feature_dim, edge_feature_dim, hidden_dim1,hidden_dim2,aggr,num_conv_layers):\n",
    "        super(MolecularGCN2, self).__init__()\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        edge_fc1 = nn.Linear(edge_feature_dim, node_feature_dim*hidden_dim1)\n",
    "        # jittable()でscriptに変換できるように\n",
    "        nnconv1 = NNConv(node_feature_dim, hidden_dim1, edge_fc1, aggr=aggr).jittable()\n",
    "\n",
    "        self.conv_list = nn.ModuleList()\n",
    "        self.conv_list.append(nnconv1)\n",
    "\n",
    "        for _ in range(num_conv_layers - 1):\n",
    "            edge_fc = nn.Linear(edge_feature_dim, hidden_dim1*hidden_dim1)\n",
    "            nnconv = NNConv(hidden_dim1, hidden_dim1, edge_fc, aggr=aggr).jittable()\n",
    "            self.conv_list.append(nnconv)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc2 = nn.Linear(hidden_dim2, 1)\n",
    "\n",
    "    def forward(self,  x, edge_index, edge_attr, batch):\n",
    "        for f in self.conv_list:\n",
    "            x = f(x=x,edge_index=edge_index, edge_attr=edge_attr)\n",
    "            x = self.activation_func(x)\n",
    "        x = global_max_pool(x,batch)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation_func(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = MolecularGCN2(61,12,num_conv_layers=5, hidden_dim1=70, hidden_dim2= 162, aggr= 'add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198655/198655 [00:11<00:00, 17385.79it/s]\n"
     ]
    }
   ],
   "source": [
    "smiles_column = df[\"SMILES\"]\n",
    "\n",
    "# ヘッダーを含むSMILESデータを作成\n",
    "smiles_with_header = 'SMILES\\n' + '\\n'.join(smiles_column)\n",
    "\n",
    "# 分子を作成\n",
    "smiles_supplier = Chem.SmilesMolSupplierFromText(smiles_with_header, delimiter=',', titleLine=True, smilesColumn=0, nameColumn=-1)\n",
    "\n",
    "# 分子データの取得\n",
    "molecules = [mol for mol in tqdm(smiles_supplier)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SMILES strings to atom features and bond features\n",
    "atom_features = [smiles_to_atom_feature(smiles) for smiles in smiles_column]\n",
    "bond_features = [smiles_to_bond_feature(smiles) for smiles in smiles_column]\n",
    "\n",
    "# Separate edge_index and edge_attr into different lists\n",
    "edge_indices, edge_attrs = zip(*bond_features)\n",
    "\n",
    "# Find the maximum number of atoms in the molecules\n",
    "max_atoms_0 = max(feature.size(0) for feature in atom_features)\n",
    "max_atoms_1 = max(feature.size(1) for feature in atom_features)\n",
    "max_edges_0 = max(index.size(0) for index in edge_indices)\n",
    "max_edges_1 = max(index.size(1) for index in edge_indices)\n",
    "max_attrs_0 = max(attr.size(0) for attr in edge_attrs)\n",
    "max_attrs_1 = max(attr.size(1) for attr in edge_attrs)\n",
    "\n",
    "# find max in dim0 and dim1\n",
    "max_size_0 = max(max_atoms_0, max_edges_0, max_attrs_0)\n",
    "max_size_1 = max(max_atoms_1, max_edges_1, max_attrs_1)\n",
    "\n",
    "# Pad the tensors to have the same size\n",
    "atom_features_padded = [torch.cat([feature, torch.zeros(max_size_0 - feature.size(0), max_size_1 - feature.size(1))]) for feature in atom_features]\n",
    "edge_indices_padded = [torch.cat([index, torch.zeros(max_size_0 - index.size(0), max_size_1 - index.size(1))]) for index in edge_indices]\n",
    "edge_attrs_padded = [torch.cat([attr, torch.zeros(max_size_0 - attr.size(0), max_size_1 - attr.size(1))]) for attr in edge_attrs]\n",
    "\n",
    "# Convert the padded atom features to a PyTorch tensor\n",
    "atom_features_tensor = torch.stack(atom_features_padded)\n",
    "\n",
    "bond_features_tensor = torch.cat([edge_indices_padded])\n",
    "\n",
    "# Convert the list to a PyTorch tensor\n",
    "bond_features_tensor = torch.stack(bond_features_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive\\デスクトップ\\MI_Academy\\Q2\\distribution\\GCNN.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(test_indices)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Create DataLoader for training and testing sets\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m TensorDataset(atom_features[train_indices], bond_features[train_indices])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m TensorDataset(atom_features[test_indices], bond_features[test_indices])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_indices, test_indices = train_test_split(range(len(molecules)), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_dataset = TensorDataset(atom_features_tensor[train_indices], bond_features_tensor[train_indices])\n",
    "test_dataset = TensorDataset(atom_features_tensor[test_indices], bond_features_tensor[test_indices])\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# モデルの構築\n",
    "model = MolecularGCN2(61, 12, num_conv_layers=5, hidden_dim1=70, hidden_dim2=162, aggr='add')\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 最適化アルゴリズムの選択\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 学習のループ\n",
    "num_epochs = 10\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        inputs, targets = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # Adjust as needed\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # エポックごとにモデルの評価\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        for data in test_loader:\n",
    "            inputs, targets = data\n",
    "            outputs = model(inputs)  # Adjust as needed\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Test Loss: {average_loss}')\n",
    "\n",
    "# モデルの保存\n",
    "with open('trained_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming your DataFrame has a target variable named 'λmax'\n",
    "target_column = df['λmax'].values.astype('float32')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, target_column, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert SMILES strings to atom features for both training and testing sets\n",
    "X_train = [smiles_to_atom_feature(smiles, res_type='tensor') for smiles in df_train['SMILES']]\n",
    "X_test = [smiles_to_atom_feature(smiles, res_type='tensor') for smiles in df_test['SMILES']]\n",
    "\n",
    "# Find the maximum number of atoms in the training and testing sets\n",
    "max_atoms_train = max(x.size(0) for x in X_train)\n",
    "max_atoms_test = max(x.size(0) for x in X_test)\n",
    "max_atoms = max(max_atoms_train, max_atoms_test)\n",
    "\n",
    "# Pad or trim the tensors to have the same size\n",
    "X_train_padded = [torch.cat([x, torch.zeros(max_atoms - x.size(0), x.size(1))]) for x in X_train]\n",
    "X_test_padded = [torch.cat([x, torch.zeros(max_atoms - x.size(0), x.size(1))]) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SMILES strings to bond features for both training and testing sets\n",
    "edge_index_train, edge_attr_train = zip(*[smiles_to_bond_feature(smiles) for smiles in df_train['SMILES']])\n",
    "edge_index_test, edge_attr_test = zip(*[smiles_to_bond_feature(smiles) for smiles in df_test['SMILES']])\n",
    "\n",
    "# Find the maximum number of bonds in the training and testing sets\n",
    "max_bonds_train = max(attr.size(0) for attr in edge_attr_train)\n",
    "max_bonds_test = max(attr.size(0) for attr in edge_attr_test)\n",
    "max_bonds = max(max_bonds_train, max_bonds_test)\n",
    "\n",
    "# Pad or trim the tensors to have the same size\n",
    "edge_attr_train_padded = [torch.cat([attr, torch.zeros(max_bonds - attr.size(0), attr.size(1))]) for attr in edge_attr_train]\n",
    "edge_attr_test_padded = [torch.cat([attr, torch.zeros(max_bonds - attr.size(0), attr.size(1))]) for attr in edge_attr_test]\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_dataset = TensorDataset(torch.stack(X_train_padded), torch.stack(edge_attr_train_padded))\n",
    "test_dataset = TensorDataset(torch.stack(X_test_padded), torch.stack(edge_attr_test_padded))\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare edge_index and edge_attr using smiles_to_bond_feature function\n",
    "edge_indices = []\n",
    "edge_attrs = []\n",
    "\n",
    "for smiles in tqdm(smiles_column):\n",
    "    edge_index, edge_attr = smiles_to_bond_feature(smiles)\n",
    "    edge_indices.append(edge_index)\n",
    "    edge_attrs.append(edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_25764\\3365594984.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_indices = [torch.tensor(idx, dtype=torch.long) for idx in edge_indices]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_25764\\3365594984.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_attrs = [torch.tensor(attr, dtype=torch.float32) for attr in edge_attrs]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive\\デスクトップ\\MI_Academy\\Q2\\distribution\\GCNN.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     inputs, edge_index, edge_attr, targets \u001b[39m=\u001b[39m data\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs, edge_index, edge_attr, batch\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)  \u001b[39m# Adjust batch as needed\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "# モデルの構築\n",
    "model = MolecularGCN2(61, 12, num_conv_layers=5, hidden_dim1=70, hidden_dim2=162, aggr='add')\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Convert edge indices and attributes to PyTorch tensors\n",
    "edge_indices = [torch.tensor(idx, dtype=torch.long) for idx in edge_indices]\n",
    "edge_attrs = [torch.tensor(attr, dtype=torch.float32) for attr in edge_attrs]\n",
    "\n",
    "# 最適化アルゴリズムの選択\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_indices = list(range(len(molecules) // 2))  # adjust the split as needed\n",
    "test_indices = list(range(len(molecules) // 2, len(molecules)))\n",
    "\n",
    "# 学習のループ\n",
    "num_epochs = 10\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        inputs, edge_index, edge_attr, targets = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, edge_index, edge_attr, batch=None)  # Adjust batch as needed\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # エポックごとにモデルの評価\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        for data in test_loader:\n",
    "            inputs, edge_index, edge_attr, targets = data\n",
    "            outputs = model(inputs, edge_index, edge_attr, batch=None)  # Adjust batch as needed\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Test Loss: {average_loss}')\n",
    "\n",
    "# モデルの保存\n",
    "with open('trained_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198655/198655 [00:34<00:00, 5819.22it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\user\\OneDrive\\デスクトップ\\MI_Academy\\Q2\\distribution\\GCNN.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     inputs, edge_index, edge_attr, targets \u001b[39m=\u001b[39m data\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     inputs, edge_index, edge_attr, targets \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), edge_index\u001b[39m.\u001b[39mto(device), edge_attr\u001b[39m.\u001b[39mto(device), targets\u001b[39m.\u001b[39mto(device)  \u001b[39m# Move the data to GPU\u001b[39;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X10sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# モデルの構築\n",
    "model = MolecularGCN2(61, 12, num_conv_layers=5, hidden_dim1=70, hidden_dim2=162, aggr='add')\n",
    "model = model.to(device)  # Move the model to GPU\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 最適化アルゴリズムの選択\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 学習のループ\n",
    "num_epochs = 10\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        inputs, edge_index, edge_attr, targets = data\n",
    "        inputs, edge_index, edge_attr, targets = inputs.to(device), edge_index.to(device), edge_attr.to(device), targets.to(device)  # Move the data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, edge_index, edge_attr, batch=None)  # Adjust batch as needed\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # エポックごとにモデルの評価\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        for data in test_loader:\n",
    "            inputs, edge_index, edge_attr, targets = data\n",
    "            inputs, edge_index, edge_attr, targets = inputs.to(device), edge_index.to(device), edge_attr.to(device), targets.to(device)  # Move the data to GPU\n",
    "            outputs = model(inputs, edge_index, edge_attr, batch=None)  # Adjust batch as needed\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Test Loss: {average_loss}')\n",
    "\n",
    "# モデルの保存\n",
    "with open('trained_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [2, 42] at entry 0 and [2, 24] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive\\デスクトップ\\MI_Academy\\Q2\\distribution\\GCNN.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m edge_attr_test_padded \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mcat([attr, torch\u001b[39m.\u001b[39mzeros(max_bonds \u001b[39m-\u001b[39m attr\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), attr\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))]) \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m edge_attr_test]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Create DataLoader for training and testing sets\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m TensorDataset(torch\u001b[39m.\u001b[39mstack(X_train_padded), torch\u001b[39m.\u001b[39;49mstack(edge_index_train), torch\u001b[39m.\u001b[39mstack(edge_attr_train_padded), torch\u001b[39m.\u001b[39mfrom_numpy(y_train))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m TensorDataset(torch\u001b[39m.\u001b[39mstack(X_test_padded), torch\u001b[39m.\u001b[39mstack(edge_index_test), torch\u001b[39m.\u001b[39mstack(edge_attr_test_padded), torch\u001b[39m.\u001b[39mfrom_numpy(y_test))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive/%E3%83%87%E3%82%B9%E3%82%AF%E3%83%88%E3%83%83%E3%83%97/MI_Academy/Q2/distribution/GCNN.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [2, 42] at entry 0 and [2, 24] at entry 1"
     ]
    }
   ],
   "source": [
    "# Convert SMILES strings to bond features for both training and testing sets\n",
    "edge_index_train, edge_attr_train = zip(*[smiles_to_bond_feature(smiles) for smiles in df_train['SMILES']])\n",
    "edge_index_test, edge_attr_test = zip(*[smiles_to_bond_feature(smiles) for smiles in df_test['SMILES']])\n",
    "\n",
    "# Find the maximum number of bonds in the training and testing sets\n",
    "max_bonds_train = max(attr.size(0) for attr in edge_attr_train)\n",
    "max_bonds_test = max(attr.size(0) for attr in edge_attr_test)\n",
    "max_bonds = max(max_bonds_train, max_bonds_test)\n",
    "\n",
    "# Pad or trim the tensors to have the same size\n",
    "edge_attr_train_padded = [torch.cat([attr, torch.zeros(max_bonds - attr.size(0), attr.size(1))]) for attr in edge_attr_train]\n",
    "edge_attr_test_padded = [torch.cat([attr, torch.zeros(max_bonds - attr.size(0), attr.size(1))]) for attr in edge_attr_test]\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_dataset = TensorDataset(torch.stack(X_train_padded), torch.stack(edge_index_train), torch.stack(edge_attr_train_padded), torch.from_numpy(y_train))\n",
    "test_dataset = TensorDataset(torch.stack(X_test_padded), torch.stack(edge_index_test), torch.stack(edge_attr_test_padded), torch.from_numpy(y_test))\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 以下のコードは変更なし...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# モデルの構築\n",
    "model = MolecularGCN2(61, 12, num_conv_layers=5, hidden_dim1=70, hidden_dim2=162, aggr='add')\n",
    "model = model.to(device)  # Move the model to GPU\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 最適化アルゴリズムの選択\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 学習のループ\n",
    "num_epochs = 10\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        inputs, edge_index, edge_attr, targets = data\n",
    "        inputs, edge_index, edge_attr, targets = inputs.to(device), edge_index.to(device), edge_attr.to(device), targets.to(device)  # Move the data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, edge_index, edge_attr, batch=None)  # Adjust batch as needed\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # エポックごとにモデルの評価\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0.0\n",
    "        for data in test_loader:\n",
    "            inputs, edge_index, edge_attr, targets = data\n",
    "            inputs, edge_index, edge_attr, targets = inputs.to(device), edge_index.to(device), edge_attr.to(device), targets.to(device)  # Move the data to GPU\n",
    "            outputs = model(inputs, edge_index, edge_attr, batch=None)  # Adjust batch as needed\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Test Loss: {average_loss}')\n",
    "\n",
    "# モデルの保存\n",
    "with open('trained_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
